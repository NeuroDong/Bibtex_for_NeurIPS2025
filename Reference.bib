
@Article{LeCun2015,
	author={LeCun, Yann
	and Bengio, Yoshua
	and Hinton, Geoffrey},
	title={Deep learning},
	journal={Nature},
	year={2015},
	month={May},
	day={01},
	volume={521},
	number={7553},
	pages={436-444},
	abstract={Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	issn={1476-4687},
	doi={10.1038/nature14539},
	url={https://doi.org/10.1038/nature14539}
}

@inproceedings{NIPS1994_24896ee4,
	author = {Alexander, Jay and Mozer, Michael C},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {G. Tesauro and David S. Touretzky and Todd K. Leen},
	pages = {609--616},
	publisher = {MIT Press},
	title = {Template-Based Algorithms for Connectionist Rule Extraction},
	url = {https://proceedings.neurips.cc/paper_files/paper/1994/file/24896ee4c6526356cc127852413ea3b4-Paper.pdf},
	volume = {7},
	year = {1995},
	address = {Cambridge, MA}
}

@book{bower2012book,
	title={The Book of GENESIS: Exploring Realistic Neural Models with the GEneral NEural SImulation System},
	author={James M. Bower and Beeman, D.},
	isbn={9781461216346},
	lccn={97033270},
	url={https://books.google.co.jp/books?id=f4PTBwAAQBAJ},
	year={1995},
	publisher={TELOS/Springer--Verlag},
	address = {New York}
}



@article {Hasselmo5249,
	author = {Hasselmo, Michael E and Schnell, E and Barkai, E},
	title = {Dynamics of learning and recall at excitatory recurrent synapses and cholinergic modulation in rat hippocampal region CA3},
	volume = {15},
	number = {7},
	pages = {5249--5262},
	year = {1995},
	doi = {10.1523/JNEUROSCI.15-07-05249.1995},
	publisher = {Society for Neuroscience},
	abstract = {Hippocampal region CA3 contains strong recurrent excitation mediated by synapses of the longitudinal association fibers. These recurrent excitatory connections may play a dominant role in determining the information processing characteristics of this region. However, they result in feedback dynamics that may cause both runaway excitatory activity and runaway synaptic modification. Previous models of recurrent excitation have prevented unbounded activity using biologically unrealistic techniques. Here, the activation of feedback inhibition is shown to prevent unbounded activity, allowing stable activity states during recall and learning. In the model, cholinergic suppression of synaptic transmission at excitatory feedback synapses is shown to determine the extent to which activity depends upon new features of the afferent input versus components of previously stored representations. Experimental work in brain slice preparations of region CA3 demonstrates the cholinergic suppression of synaptic transmission in stratum radiatum, which contains synapses of the longitudinal association fibers.},
	issn = {0270-6474},
	URL = {https://www.jneurosci.org/content/15/7/5249},
	eprint = {https://www.jneurosci.org/content/15/7/5249.full.pdf},
	journal = {Journal of Neuroscience}
}
